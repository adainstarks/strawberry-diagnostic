#!/usr/bin/env python3
"""
Generate MiniGPT-4 stage-2 JSONL with ONE full diagnostic report per image (doctor-grade, verbose, visual-only).

Changes vs prior:
- Removed class-specific REQUIRED_CUES enforcement (no keyword gating).
- Kept: label hard-lock, “visible organs” declaration + enforcement, contradiction blocking.
- Broader, more detailed reports: 5–9 sentences.
- Zero-input human turn ("<Img><ImageHere></Img>") to train image-only behavior.
"""

import argparse, base64, json, logging, os, sys, time, re
from pathlib import Path
from typing import Set

VALID_LABELS = {"drought","frost","healthy","overwatered","root_rot"}
DEFAULT_MODEL = os.getenv("OPENAI_VISION_MODEL", "gpt-4o")
MAX_RETRIES = 4
BACKOFF = 1.25
DEFAULT_SLEEP = 0.6
MIN_SENT, MAX_SENT = 5, 9  # richer paragraphs

# Phrases that contradict the label (blocked for non-healthy)
NEGATIONS = {
    "frost": ["no frost damage", "appears healthy", "no blackened", "no necrosis", "no freeze damage"],
    "drought": ["soil not dry", "no dryness", "no wilt"],
    "overwatered": ["not wet", "no water-logging", "dry soil"],
    "root_rot": ["roots look healthy", "no rot", "no decay", "crown healthy"],
}

# Organs we track for visibility/mention checks
MENTION_PATTERNS = {
    "roots": re.compile(r"\broots?\b", re.IGNORECASE),
    "crown": re.compile(r"\bcrown\b", re.IGNORECASE),
    "leaves": re.compile(r"\bleaves?\b|\bleaf\b", re.IGNORECASE),
    "fruit": re.compile(r"\bfruit\b|\bberry\b|\berries\b|\bachenes?\b", re.IGNORECASE),
    "flowers": re.compile(r"\bflowers?\b|\bblossoms?\b", re.IGNORECASE),
    "soil/media": re.compile(r"\bsoil\b|\bsubstrate\b|\bmedia\b|\bmulch\b", re.IGNORECASE),
}

def organs_mentioned(text: str):
    found = set()
    for organ, pat in MENTION_PATTERNS.items():
        if pat.search(text):
            found.add(organ)
    return found

def normalize_visible(lst):
    norm = set()
    for x in lst or []:
        t = str(x).strip().lower()
        if t in {"root","roots"}: norm.add("roots")
        elif t in {"crown"}: norm.add("crown")
        elif t in {"leaf","leaves","foliage"}: norm.add("leaves")
        elif t in {"fruit","berry","berries"}: norm.add("fruit")
        elif t in {"flower","flowers","blossom","blossoms"}: norm.add("flowers")
        elif t in {"soil","media","substrate","mulch"}: norm.add("soil/media")
    return norm

def setup_logger(log_file: Path):
    log_file.parent.mkdir(parents=True, exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)s | %(message)s",
        handlers=[logging.FileHandler(log_file, encoding="utf-8"),
                  logging.StreamHandler(sys.stdout)],
    )

def to_data_url(p: Path) -> str:
    mime = {
        ".jpg":"image/jpeg",".jpeg":"image/jpeg",".png":"image/png",
        ".bmp":"image/bmp",".webp":"image/webp",".gif":"image/gif",
        ".tif":"image/tiff",".tiff":"image/tiff"
    }.get(p.suffix.lower(), "image/jpeg")
    b64 = base64.b64encode(p.read_bytes()).decode("utf-8")
    return f"data:{mime};base64,{b64}"

def load_done_images(jsonl_path: Path) -> Set[str]:
    done: Set[str] = set()
    if not jsonl_path.exists():
        return done
    with jsonl_path.open("r", encoding="utf-8") as f:
        for line in f:
            try:
                obj = json.loads(line)
                img = obj.get("image")
                if isinstance(img, str):
                    done.add(img)
            except Exception:
                continue
    return done

def build_system_prompt() -> str:
    return """You are a strawberry plant diagnostician.

Rules:
1) The diagnosis label is PRE-SET and MUST be used exactly as given.
2) Base EVERYTHING ONLY on what is visible in the image. No weather/sensor history; no speculation beyond visible plausibility.
3) First, determine which plant organs are clearly visible (choose from: leaves, flowers, fruit, stems, crown, roots, soil/media, mulch, container/bed hardware, background). Then write ONE professional report of 5–9 sentences (broad and detailed).
4) Order: begin with 'Diagnosis: <label>.' then (a) 3–6 concrete visual clues actually seen (use precise descriptors: texture, color, distribution), (b) likely cause from those clues, (c) 2–3 actionable remediation steps with parameters (depth, frequency, cover, etc.), (d) what to monitor next week (clear, measurable).
5) Prefer irrigation, airflow, mulch, shading, drainage, sanitation; avoid chemicals unless visuals clearly warrant them.
6) Return STRICT JSON: {"visible": ["..."], "report": "<text>"} with no markdown or extra keys. The 'visible' list must only include organs clearly seen in the image.
"""

def build_user_payload(label: str) -> str:
    return json.dumps({
        "label": label,
        "note": "Use the fixed label. Describe only what is actually visible. Output one broad, detailed doctor report."
    }, ensure_ascii=False)

def validate_report(report: str, label: str, visible_declared: Set[str]) -> None:
    t = report.strip()
    # 1) Label prefix
    exp = f"Diagnosis: {label}"
    if not t.startswith(exp):
        raise ValueError(f"Report must start with '{exp}'")
    # 2) Sentence richness
    sents = [s for s in t.replace("\n"," ").split(".") if s.strip()]
    if not (MIN_SENT <= len(sents) <= MAX_SENT):
        raise ValueError(f"Report length outside {MIN_SENT}-{MAX_SENT} sentences")
    # 3) Contradiction phrases
    negs = NEGATIONS.get(label, [])
    if label != "healthy" and any(neg in t.lower() for neg in negs):
        raise ValueError(f"Report contradicts label '{label}'")
    # 4) Organ mentions must be subset of declared visible organs
    mentioned = organs_mentioned(t)
    if mentioned and not mentioned.issubset(visible_declared):
        missing = mentioned - visible_declared
        raise ValueError(f"Report references non-declared organs: {sorted(missing)}")

def call_openai_image_report(client, model: str, image: Path, label: str, temperature: float) -> str:
    system = build_system_prompt()
    user_payload = build_user_payload(label)
    data_url = to_data_url(image)

    for attempt in range(1, MAX_RETRIES + 1):
        try:
            resp = client.chat.completions.create(
                model=model,
                temperature=temperature if attempt < 3 else min(0.8, temperature + 0.2),
                messages=[
                    {"role":"system","content": system},
                    {"role":"user","content":[
                        {"type":"text","text": user_payload},
                        {"type":"image_url","image_url":{"url": data_url}}
                    ]}
                ],
            )
            txt = resp.choices[0].message.content.strip()
            # Parse JSON; salvage substring if needed
            try:
                obj = json.loads(txt)
            except Exception:
                start, end = txt.find("{"), txt.rfind("}")
                if start >= 0 and end > start:
                    obj = json.loads(txt[start:end+1])
                else:
                    raise ValueError("Model did not return JSON")

            report = obj.get("report")
            visible = obj.get("visible", [])
            if not isinstance(report, str) or not report.strip():
                raise ValueError("Malformed JSON: expected 'report' as non-empty string")

            visible_norm = normalize_visible(visible)
            validate_report(report, label, visible_norm)
            return report.strip()
        except Exception as e:
            logging.warning("OpenAI call failed (%d/%d) for %s: %s", attempt, MAX_RETRIES, image.name, e)
            if attempt == MAX_RETRIES:
                raise
            time.sleep(BACKOFF ** (attempt - 1))

def iter_images(root: Path):
    for cls_dir in sorted(p for p in root.iterdir() if p.is_dir()):
        label = cls_dir.name
        if label not in VALID_LABELS:
            logging.warning("Skipping non-labeled dir: %s", cls_dir)
            continue
        for img in sorted(cls_dir.rglob("*")):
            if img.suffix.lower() in (".jpg",".jpeg",".png",".bmp",".webp",".gif",".tif",".tiff"):
                yield img, label

def setup_and_get_client():
    if not os.getenv("OPENAI_API_KEY"):
        sys.exit("OPENAI_API_KEY is not set.")
    from openai import OpenAI
    return OpenAI()

def main():
    ap = argparse.ArgumentParser("Generate single diagnostic reports for MiniGPT-4 stage-2 (doctor-grade verbose).")
    ap.add_argument("--img-root", type=Path, default=Path("data/train"))
    ap.add_argument("--out", type=Path, default=Path("datasets/strawberry_stage2_train.jsonl"))
    ap.add_argument("--model", type=str, default=DEFAULT_MODEL)
    ap.add_argument("--temperature", type=float, default=0.4)
    ap.add_argument("--sleep", type=float, default=DEFAULT_SLEEP)
    ap.add_argument("--log-file", type=Path, default=Path("logs/generate_stage2_reports.log"))
    args = ap.parse_args()

    client = setup_and_get_client()
    setup_logger(args.log_file)
    args.out.parent.mkdir(parents=True, exist_ok=True)

    done = load_done_images(args.out)
    logging.info("Resuming: %d images already present in %s", len(done), args.out)

    processed = written = 0
    with args.out.open("a", encoding="utf-8") as out:
        for img, label in iter_images(args.img_root):
            processed += 1
            img_str = str(img)
            if img_str in done:
                continue
            try:
                report = call_openai_image_report(client, args.model, img, label, args.temperature)
                rec = {
                    "image": img_str,
                    "conversations": [
                        {"from":"human", "value":"<Img><ImageHere></Img>"},
                        {"from":"assistant", "value": report}
                    ]
                }
                out.write(json.dumps(rec, ensure_ascii=False) + "\n")
                written += 1
                logging.info("[OK] %s -> 1 report", img.relative_to(args.img_root))
            except Exception as e:
                logging.error("[FAIL] %s: %s", img, e)
            time.sleep(args.sleep)

    logging.info("DONE. Wrote %d new reports across %d images -> %s", written, processed, args.out)

if __name__ == "__main__":
    main()
